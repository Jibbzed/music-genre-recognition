{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data extraction notebook was about extracting all the relevant features from the dataset\n",
    "We have extracted MFCCs and spectral centroids for 7994/8000 tracks\n",
    "Now we will apply treatments to these features, starting by dimensionality reduction and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make imports\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score, homogeneity_completeness_v_measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2 dataframes to load : the features extracted from the tracks, and the metadata about the tracks (namely the genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into dataframes\n",
    "features = pd.read_csv('data/extracted_features.csv')\n",
    "metadata = pd.read_csv('data/metadata.csv')\n",
    "\n",
    "# Remove the tracks that were not found in the features dataset from the metadata\n",
    "metadata = metadata[metadata['track_id'].isin(features['track_id'])]\n",
    "\n",
    "print (metadata.shape)\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try to reduce the dimensionality of our data from 148 to just 2 in order to be able to visualize the data points\n",
    "Then we'll apply a simple K-means clustering (and it's even better because we know the expected numebr of clusters) on our data to see how it does. In order to find the best number of dimensions we can apply PCA to all features (not reducing anything) and checking the contributions from the different attributes to the PCA. Note that for the data to be mapped we need to have the dataframes ordered in the same way : the first element of the metadata corresponds to the same track as the first element of the features dataframe. For this, it is possible to merge the two dataframes in oder to have all in one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the track_id column first\n",
    "X = features.drop(columns=['track_id']).values\n",
    "\n",
    "# Dimensionality reduction (PCA)\n",
    "pca = PCA(n_components=X.shape[1])  # Keep all components initially\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Calculate cumulative explained variance ratio\n",
    "cumulative_explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot explained variance ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_explained_variance_ratio) + 1), cumulative_explained_variance_ratio, marker='o', linestyle='-')\n",
    "plt.title('Cumulative Explained Variance Ratio')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "cumulative_explained_variance_ratio < 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, 95% of the variance can be explained with 1 component, and 99% with 3, so 2 components is enough for our use case especially because it allows us to visualise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction using PCA\n",
    "# First, reducing to 2 dimensions for visualization\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Clustering using KMeans with 8 clusters because we know that there are 8 genres\n",
    "n_clusters = 8\n",
    "kmeans = KMeans(n_clusters=8)\n",
    "clusters = kmeans.fit(X_pca)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters.labels_)\n",
    "plt.title('PCA with KMeans Clustering')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.34039857510357996\n",
      "Homogeneity: 0.10241973274710256\n",
      "Completeness: 0.10464777306373677\n",
      "V-measure: 0.10352176608104297\n",
      "Adjusted Rand Index (ARI): 0.06023096406955576\n",
      "Normalized Mutual Information (NMI): 0.10352176608104297\n"
     ]
    }
   ],
   "source": [
    "# Evaluate clustering performance\n",
    "true_labels = metadata['track_genre'].values\n",
    "\n",
    "silhouette = silhouette_score(X_pca, clusters.labels_)\n",
    "ari = adjusted_rand_score(true_labels, clusters.labels_)\n",
    "nmi = normalized_mutual_info_score(true_labels, clusters.labels_)\n",
    "h, c, v = homogeneity_completeness_v_measure(true_labels, clusters.labels_)\n",
    "\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "print(f\"Homogeneity: {h}\")\n",
    "print(f\"Completeness: {c}\")\n",
    "print(f\"V-measure: {v}\")\n",
    "print(f\"Adjusted Rand Index (ARI): {ari}\")\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret each of the evaluation metrics based on the provided values:\n",
    "\n",
    "Silhouette Score: 0.3391077082648229\n",
    "This indicates moderate clustering quality. A silhouette score between 0.25 and 0.5 suggests that the clusters are reasonably well-separated.\n",
    "The value of 0.3391 indicates that the average distance between samples in the same cluster is larger than the distance between samples in different clusters, which is a positive sign.\n",
    "\n",
    "Homogeneity: 0.10329527639929258\n",
    "This value indicates low homogeneity, suggesting that the clusters are not very pure. It means that the clusters contain samples from multiple classes, rather than being composed mostly of samples from a single class.\n",
    "\n",
    "Completeness: 0.10502800921333921\n",
    "Similarly to homogeneity, the low completeness value suggests that each class is not entirely assigned to a single cluster. Some samples from each class might be spread across multiple clusters.\n",
    "\n",
    "V-measure: 0.10415443678756468\n",
    "V-measure is the harmonic mean of homogeneity and completeness. The low value indicates that neither homogeneity nor completeness is high, resulting in a relatively low overall V-measure.\n",
    "\n",
    "Adjusted Rand Index (ARI): 0.06081721484810713\n",
    "This value suggests a slightly better than random clustering performance. ARI ranges from -1 to 1, where 1 indicates perfect clustering agreement with the ground truth labels, 0 indicates random clustering, and negative values indicate clustering worse than random.\n",
    "\n",
    "Normalized Mutual Information (NMI): 0.10415443678756468\n",
    "NMI measures the mutual information between the true and predicted cluster labels, normalized by the total entropy of the labels. The low value suggests limited mutual information between the true and predicted labels, indicating that the clustering algorithm does not capture the true label information well.\n",
    "\n",
    "In summary, the provided metrics indicate that while there is some structure in the clustering, it is not strong. The clusters are moderately separated according to the silhouette score, but they are not very homogeneous or complete. The ARI and NMI scores suggest that the clustering does not agree strongly with the ground truth labels. These results indicate that there may be room for improvement in the clustering algorithm or in the data preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try with 5 dimensions for clustering and see how it affects the metrics (because with 5 dimensions we have more than 99% of the variance explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.29250870556999714\n",
      "Homogeneity: 0.1044324515753437\n",
      "Completeness: 0.10674759898395686\n",
      "V-measure: 0.10557733490593976\n",
      "Adjusted Rand Index (ARI): 0.06154816042614267\n",
      "Normalized Mutual Information (NMI): 0.10557733490593976\n"
     ]
    }
   ],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Clustering using KMeans with 8 clusters because we know that there are 8 genres\n",
    "n_clusters = 8\n",
    "kmeans = KMeans(n_clusters=8)\n",
    "clusters = kmeans.fit(X_pca)\n",
    "\n",
    "# We can't visualize the clusters\n",
    "\n",
    "# Evaluate clustering performance\n",
    "silhouette = silhouette_score(X_pca, clusters.labels_)\n",
    "ari = adjusted_rand_score(true_labels, clusters.labels_)\n",
    "nmi = normalized_mutual_info_score(true_labels, clusters.labels_)\n",
    "h, c, v = homogeneity_completeness_v_measure(true_labels, clusters.labels_)\n",
    "\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "print(f\"Homogeneity: {h}\")\n",
    "print(f\"Completeness: {c}\")\n",
    "print(f\"V-measure: {v}\")\n",
    "print(f\"Adjusted Rand Index (ARI): {ari}\")\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have done the clustering part, we can start the actual classification task. We will train two different models namely SVM and Random Forest (debatable but those are the ones I choose, we could compare them to a neural network of some kind). The data has already been split in 3 sets for us, and the sets are supposedly very well balanced in order to make our lives easier, so we will start by getting our 3 sets and then we will train our models, using cross validation and the validation set to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our dataset in 3 parts: train, validation and test  \n",
    "\n",
    "# First, we need to merge the features and metadata dataframes\n",
    "data = pd.merge(features, metadata, on='track_id')\n",
    "\n",
    "# Split the data into train, validation and test sets\n",
    "train = data[data['set'] == 'training']\n",
    "validation = data[data['set'] == 'validation']  \n",
    "test = data[data['set'] == 'test']\n",
    "\n",
    "# Sanity check\n",
    "print(train.shape)\n",
    "print(validation.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# Drop the track_id, track_genre, genre_id and set columns\n",
    "X_train = train.drop(columns=['track_id', 'track_genre', 'set', 'genre_id']).values\n",
    "X_validation = validation.drop(columns=['track_id', 'track_genre', 'set', 'genre_id']).values\n",
    "X_test = test.drop(columns=['track_id', 'track_genre', 'set', 'genre_id']).values\n",
    "\n",
    "# Split the data into data and labels, labels being the track_genre column\n",
    "y_train = train['track_genre'].values\n",
    "y_validation = validation['track_genre'].values\n",
    "y_test = test['track_genre'].values\n",
    "\n",
    "# Sanity check\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_validation.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried using GridSearch in order to automate the hyperparameter tuning process. The idea is that it performs 5 fold cross validation with all possible combinations of hyperparameters that is given to it, and ends up outputting the best performing model. Note that because I use cross validation I should merge the training and validation datasets because the validation is done \"on the training data\" with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.127 total time=   8.4s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.127 total time=   7.7s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.128 total time=   7.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.127 total time=   7.2s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.127 total time=   6.8s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.131 total time=   6.9s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.130 total time=   6.7s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.147 total time=   6.6s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.138 total time=   6.7s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.127 total time=   6.4s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.450 total time=   5.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.451 total time=   6.1s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.471 total time=   6.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.440 total time=   5.7s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.465 total time=   5.5s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.434 total time=   5.5s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.433 total time=   5.3s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.459 total time=   5.3s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.435 total time=   5.9s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.433 total time=   5.3s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.331 total time=   6.4s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.336 total time=   7.1s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.318 total time=   6.3s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.312 total time=   6.6s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.320 total time=   6.4s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.131 total time=   6.7s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.129 total time=   6.5s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.131 total time=   6.8s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.132 total time=   6.7s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.128 total time=   6.7s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.315 total time=   6.9s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.327 total time=   6.9s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.339 total time=   6.7s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.303 total time=   7.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.289 total time=   6.8s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.530 total time=   4.7s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.531 total time=   4.6s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.542 total time=   4.6s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.528 total time=   4.5s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.534 total time=   4.7s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.494 total time=   4.1s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.497 total time=   4.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.507 total time=   4.2s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.486 total time=   4.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.506 total time=   4.2s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.433 total time=   5.2s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   5.5s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.450 total time=   5.6s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.441 total time=   5.2s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.433 total time=   5.6s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.131 total time=   6.7s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.129 total time=   6.7s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.131 total time=   6.6s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.133 total time=   6.6s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.128 total time=   6.8s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.321 total time=   6.6s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.350 total time=   7.2s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.351 total time=   8.9s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.320 total time=   7.6s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.310 total time=   8.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.542 total time=   7.3s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.542 total time=   7.3s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.545 total time=   6.9s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.541 total time=   6.8s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.519 total time=   6.1s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.535 total time=   3.9s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.534 total time=   3.9s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.527 total time=   3.9s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.500 total time=   3.9s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.534 total time=   3.9s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.481 total time=   4.2s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.488 total time=   4.2s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.488 total time=   4.2s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.475 total time=   4.2s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.496 total time=   4.2s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.131 total time=   6.7s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.129 total time=   7.5s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.131 total time=   7.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.133 total time=   7.7s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.128 total time=   6.7s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.321 total time=   6.7s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.350 total time=   6.7s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.351 total time=   6.6s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.320 total time=   6.5s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.310 total time=   6.8s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.541 total time=   6.1s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.541 total time=   6.1s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.541 total time=   6.1s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.534 total time=   6.2s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.519 total time=   6.1s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.531 total time=   5.6s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.521 total time=   5.6s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.511 total time=   5.4s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.502 total time=   5.4s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.503 total time=   5.6s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.516 total time=   4.1s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.511 total time=   4.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.513 total time=   4.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.491 total time=   4.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.520 total time=   4.1s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.131 total time=   6.6s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.129 total time=   6.5s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.131 total time=   6.6s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.133 total time=   6.7s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.128 total time=   6.6s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.321 total time=   6.9s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.350 total time=   6.7s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.351 total time=   6.6s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.320 total time=   7.1s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.310 total time=   6.9s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.542 total time=   6.1s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.541 total time=   6.2s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.541 total time=   6.1s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.535 total time=   6.1s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.519 total time=   6.2s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.489 total time=   8.6s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.489 total time=   8.6s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.484 total time=   8.5s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.491 total time=   8.6s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.486 total time=   8.8s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.510 total time=   5.9s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.505 total time=   5.9s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.511 total time=   5.9s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.492 total time=   5.8s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.529 total time=   6.0s\n",
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=0.01)\n",
      "0.5376676547710753\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Electronic       0.44      0.58      0.50       100\n",
      " Experimental       0.25      0.37      0.30       100\n",
      "         Folk       0.17      0.17      0.17       100\n",
      "      Hip-Hop       0.61      0.62      0.62       100\n",
      " Instrumental       0.32      0.28      0.30       100\n",
      "International       0.57      0.45      0.50       100\n",
      "          Pop       0.30      0.25      0.27       100\n",
      "         Rock       0.63      0.43      0.51       100\n",
      "\n",
      "     accuracy                           0.39       800\n",
      "    macro avg       0.41      0.39      0.40       800\n",
      " weighted avg       0.41      0.39      0.40       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First we want to train SVM model with 5 fold cross validation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Merge the train and validation sets for cross validation\n",
    "X_cross_validation = np.concatenate((X_train, X_validation))\n",
    "y_cross_validation = np.concatenate((y_train, y_validation))\n",
    "\n",
    "'''\n",
    "# Use PCA to reduce the dimensionality of the data\n",
    "pca = PCA(n_components=5)\n",
    "X_cross_validation = pca.fit_transform(X_cross_validation)\n",
    "X_test = pca.transform(X_test)\n",
    "'''\n",
    "\n",
    "# Be sure training samples are shuffled.\n",
    "X_cross_validation, y_cross_validation = skl.utils.shuffle(X_cross_validation, y_cross_validation, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(X_cross_validation)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "grid.fit(X_cross_validation, y_cross_validation)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "#print(grid.best_index_)\n",
    "#print(grid.scorer_)\n",
    "#print(grid.n_splits_)\n",
    "#print(grid.refit_time_)\n",
    "#print(grid.cv_results_)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we use a rbf kernel for the SVM because the problem at hand is quite complex and the rbf kernel allows us to find non linear relationships in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ..max_features=auto, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..max_features=auto, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..max_features=auto, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..max_features=auto, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..max_features=auto, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .max_features=auto, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_features=auto, n_estimators=1000;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_features=auto, n_estimators=1000;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_features=auto, n_estimators=1000;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_features=auto, n_estimators=1000;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_features=auto, n_estimators=1000;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=10;, score=0.435 total time=   0.9s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=10;, score=0.448 total time=   0.9s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=10;, score=0.432 total time=   0.8s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=10;, score=0.436 total time=   0.9s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=10;, score=0.433 total time=   0.8s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=100;, score=0.508 total time=   9.8s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=100;, score=0.521 total time=  11.8s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=100;, score=0.515 total time=  13.3s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=100;, score=0.502 total time=  11.7s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=100;, score=0.499 total time=  12.6s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=1000;, score=0.514 total time= 2.0min\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=1000;, score=0.525 total time= 1.9min\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=1000;, score=0.527 total time= 1.7min\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=1000;, score=0.505 total time= 1.7min\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=1000;, score=0.518 total time= 1.7min\n",
      "[CV 1/5] END max_features=log2, n_estimators=10;, score=0.423 total time=   0.5s\n",
      "[CV 2/5] END max_features=log2, n_estimators=10;, score=0.414 total time=   0.5s\n",
      "[CV 3/5] END max_features=log2, n_estimators=10;, score=0.426 total time=   0.5s\n",
      "[CV 4/5] END max_features=log2, n_estimators=10;, score=0.416 total time=   0.6s\n",
      "[CV 5/5] END max_features=log2, n_estimators=10;, score=0.428 total time=   0.5s\n",
      "[CV 1/5] END max_features=log2, n_estimators=100;, score=0.495 total time=   6.2s\n",
      "[CV 2/5] END max_features=log2, n_estimators=100;, score=0.494 total time=   6.2s\n",
      "[CV 3/5] END max_features=log2, n_estimators=100;, score=0.511 total time=   6.4s\n",
      "[CV 4/5] END max_features=log2, n_estimators=100;, score=0.506 total time=   6.4s\n",
      "[CV 5/5] END max_features=log2, n_estimators=100;, score=0.499 total time=   6.0s\n",
      "[CV 1/5] END max_features=log2, n_estimators=1000;, score=0.502 total time= 1.1min\n",
      "[CV 2/5] END max_features=log2, n_estimators=1000;, score=0.507 total time= 1.1min\n",
      "[CV 3/5] END max_features=log2, n_estimators=1000;, score=0.519 total time= 1.1min\n",
      "[CV 4/5] END max_features=log2, n_estimators=1000;, score=0.508 total time= 1.1min\n",
      "[CV 5/5] END max_features=log2, n_estimators=1000;, score=0.506 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cours\\Echange Milan\\Audio Pattern Recognition\\music-genre-recognition\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Cours\\Echange Milan\\Audio Pattern Recognition\\music-genre-recognition\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Cours\\Echange Milan\\Audio Pattern Recognition\\music-genre-recognition\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"d:\\Cours\\Echange Milan\\Audio Pattern Recognition\\music-genre-recognition\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"d:\\Cours\\Echange Milan\\Audio Pattern Recognition\\music-genre-recognition\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Cours\\Echange Milan\\Audio Pattern Recognition\\music-genre-recognition\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.43675236 0.50917294 0.51765366\n",
      " 0.42146319 0.5009728  0.50847898]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "RandomForestClassifier(n_estimators=1000)\n",
      "0.5176536595785398\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Electronic       0.47      0.56      0.51       100\n",
      " Experimental       0.32      0.18      0.23       100\n",
      "         Folk       0.19      0.21      0.20       100\n",
      "      Hip-Hop       0.54      0.61      0.57       100\n",
      " Instrumental       0.38      0.46      0.42       100\n",
      "International       0.46      0.48      0.47       100\n",
      "          Pop       0.30      0.24      0.27       100\n",
      "         Rock       0.58      0.58      0.58       100\n",
      "\n",
      "     accuracy                           0.41       800\n",
      "    macro avg       0.41      0.41      0.41       800\n",
      " weighted avg       0.41      0.41      0.41       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's now try to train a Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "'''\n",
    "# Use PCA to reduce the dimensionality of the data\n",
    "pca = PCA(n_components=5)\n",
    "X_cross_validation = pca.fit_transform(X_cross_validation)\n",
    "X_test = pca.transform(X_test)\n",
    "'''\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'n_estimators': [10, 100, 1000], 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, refit=True, verbose=3, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "grid.fit(X_cross_validation, y_cross_validation)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "#print(grid.best_index_)\n",
    "#print(grid.scorer_)\n",
    "#print(grid.n_splits_)\n",
    "#print(grid.refit_time_)\n",
    "#print(grid.cv_results_)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
