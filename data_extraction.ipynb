{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import librosa\n",
    "import librosa.display\n",
    "import ast\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a helper function to load the csv files : taken from the FMA repo from where I got the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filepath):\n",
    "\n",
    "    filename = os.path.basename(filepath)\n",
    "\n",
    "    if 'features' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'echonest' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'genres' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0)\n",
    "\n",
    "    if 'tracks' in filename:\n",
    "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "\n",
    "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
    "                   ('track', 'genres'), ('track', 'genres_all')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "                   ('album', 'date_created'), ('album', 'date_released'),\n",
    "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "                   ('artist', 'active_year_end')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "        SUBSETS = ('small', 'medium', 'large')\n",
    "        try:\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                    'category', categories=SUBSETS, ordered=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # the categories and ordered arguments were removed in pandas 0.25\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                     pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "\n",
    "        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
    "                   ('album', 'type'), ('album', 'information'),\n",
    "                   ('artist', 'bio')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].astype('category')\n",
    "\n",
    "        return tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load metadata and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = load('fma_metadata/tracks.csv')\n",
    "genres = load('fma_metadata/genres.csv')\n",
    "features = load('fma_metadata/features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract only the relevant metadata about the tracks in the \"small\" set because that is the one we will be working with : we will be extracting the track id, track genre, genre id and the set (training, test, validation) to which the sample belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         track_genre       set genre_id\n",
      "track_id                               \n",
      "2            Hip-Hop  training       21\n",
      "5            Hip-Hop  training       21\n",
      "10               Pop  training       10\n",
      "140             Folk  training       17\n",
      "141             Folk  training       17\n"
     ]
    }
   ],
   "source": [
    "small = tracks[tracks['set', 'subset'] <= 'small']\n",
    "data = {\n",
    "    'track_genre': small['track', 'genre_top'],\n",
    "    'set': small['set', 'split']\n",
    "}\n",
    "dataset = pd.DataFrame(data)\n",
    "# Extract the genre_id from the genre name\n",
    "dataset = dataset.assign(genre_id=dataset['track_genre'].apply(lambda x: genres[genres['title'] == x].index[0]))\n",
    "\n",
    "print(dataset.head())\n",
    "\n",
    "# Export the dataset to a csv file\n",
    "dataset.to_csv('data/metadata.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to extract features from the audio files, therefore we will need to be able to list all of their paths, knowing that they are distributed in different folders under \"fma_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = r'.\\\\fma_small\\\\'\n",
    "# list to store files name\n",
    "pathlist = []\n",
    "# use of os.walk to get all the files in the directory recursively\n",
    "for (dir_path, dir_names, file_names) in os.walk(dir_path):\n",
    "    # to avoid problems, we get the absolute path of the files (which requires a little \"trick\"), and we only keep the mp3 files\n",
    "    pathlist.extend(os.path.abspath(os.path.join(dir_path, file)) for file in file_names if file.endswith('.mp3'))\n",
    "print(pathlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then need to go through all the files, extracting the relevant features for each file, and storing them in a dataframe, associating the file with the track_id (the track_id being the name of the file stripped from all the 0's and the extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to code the feature extraction function and append all the features into a dataframe with the track_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the feature extraction, I will for the moment extract spectral centroids and MFCCs because they seem to be giving quite good results on audio genre classification tasks. Testing will be done on a small number of tracks to see how long it takes to extract all the features, and then I will decide if I can or not extract all features or if I have to go with the already calculated ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by default, the extraction of the features is done frame by frame on the audio, meaning that for a single audio file, we get a matrix of results. For simplicity's sake, we will follow the approach of the FMA dataset researchers, and calculate the statistical values associated to the extracted features, namely mean, standard deviation, min, max, median, skew and kurtosis\n",
    "That way we can deal with only 1 feature vector per track. Calculating all these statistical indices will allow us to still have a good depiction of the extracted features, even though we lose time dependency : we don't simply take the mean ! This approach could be discussed in the paper, but as the task is audio classification, a hollistic approach should be a good fit for us (plus we are working on a quite simple problem with only 8 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path)\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    \n",
    "    # Extract spectral centroid\n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    \n",
    "    return mfcc, centroid\n",
    "\n",
    "def calculate_statistics(features):\n",
    "    statistics = {\n",
    "        'mean': np.mean(features, axis=1),\n",
    "        'std': np.std(features, axis=1),\n",
    "        'min': np.min(features, axis=1),\n",
    "        'max': np.max(features, axis=1),\n",
    "        'kurtosis': pd.DataFrame(features).kurtosis(axis=1),\n",
    "        'skew': pd.DataFrame(features).skew(axis=1),\n",
    "        'median': np.median(features, axis=1)\n",
    "    }\n",
    "    return statistics\n",
    "\n",
    "def process_audio_files(file_paths):\n",
    "    data = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # Extract features\n",
    "            mfcc, centroid = extract_features(file_path)\n",
    "            \n",
    "            # Calculate statistics for MFCC features\n",
    "            mfcc_statistics = calculate_statistics(mfcc)\n",
    "            \n",
    "            # Calculate statistics for spectral centroid\n",
    "            centroid_statistics = calculate_statistics(centroid)\n",
    "            \n",
    "            # Store statistics and file id in a dictionary\n",
    "            # Careful : use lstrip and not just strip because it would remove all the 0s of the files ending with 0 (like 10 would become 1)\n",
    "            file_id = os.path.basename(file_path).split('.')[0].lstrip('0') # Extract track ID from file name\n",
    "            entry = {'track_id': file_id}\n",
    "            \n",
    "            # Add MFCC statistics to entry\n",
    "            for mfcc_number, mfcc_values in enumerate(mfcc):\n",
    "                for stat_name, stat_value in mfcc_statistics.items():\n",
    "                    entry[f'mfcc_{mfcc_number}_{stat_name}'] = stat_value[mfcc_number]\n",
    "            \n",
    "            # Add centroid statistics to entry\n",
    "            for stat_name, stat_value in centroid_statistics.items():\n",
    "                entry[f'centroid_{stat_name}'] = stat_value[0]  # Spectral centroid has only one value per track\n",
    "            \n",
    "            data.append(entry)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing track {os.path.basename(file_path).split('.')[0].lstrip('0')}: {e}\")\n",
    "            continue\n",
    "        \n",
    "    return data\n",
    "\n",
    "# List of file paths (replace with actual file paths)\n",
    "file_paths = [pathlist[0], pathlist[1]]\n",
    "\n",
    "# Process audio files and create dataframe\n",
    "df = pd.DataFrame(process_audio_files(file_paths))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a working method to extract all the features that I want on a list of files, I can apply it to a bigger chunk of the data to see how long it takes. Once that is done, I can start working on PCA to display the data, and on machine learning models to do the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "for i in range(100):\n",
    "    file_paths.append(pathlist[i])\n",
    "\n",
    "# Process audio files and create dataframe\n",
    "df = pd.DataFrame(process_audio_files(file_paths))\n",
    "\n",
    "df.to_csv('extracted_features.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some testing show that 100 files can be processed in around 20 seconds, meaning that all 8000 files can be processed in around 30 minutes\n",
    "In order to not have to redo the extraction everytime and be able to work on the data analysis part, I will export the dataframe into a CSV file so that I can just import it (and not waste 30 minutes)\n",
    "I will be using a \"periodic commit\" to write to the CSV file periodically and not have to redo the whole calculations every time it crashes (because it seems to be crashing at some point but I don't know exactly why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split list into chunks\n",
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        #use yield instead of return to create a generator\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "# Process files in chunks\n",
    "chunk_size = 100\n",
    "for i, chunk in enumerate(chunks(pathlist, chunk_size)):\n",
    "    print(f\"Processing chunk {i+1}...\")\n",
    "    df = pd.DataFrame(process_audio_files(chunk))\n",
    "    if i == 0:\n",
    "        # Save header only for the first chunk\n",
    "        # We can use index = False because the index is not important in this case\n",
    "        df.to_csv('data/extracted_features.csv', index=False)\n",
    "    else:\n",
    "        # Append data without header for subsequent chunks\n",
    "        df.to_csv('data/extracted_features.csv', mode='a', index=False, header=False)\n",
    "    print(f\"Saved processed data for chunk {i+1}\")\n",
    "\n",
    "print(\"All chunks processed and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, some tracks yield errors and cannot be processed\n",
    "I added a try except statement in the process_audio_files function in order to deal with that and not be interrupted everytime there is an error\n",
    "This way no need to use the try except in the main loop and I can still use my \"batch\" extraction method\n",
    "In the end we get 7994 tracks processed out of 8000 which is quite good and will not impede our ability to do further data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the features are extracted, we can actually work on the data analysis steps, namely : \n",
    "- dimensionality reduction and clustering in order to see if we can already distinguish clusters and infer \"rules\" to differentiate the different classes\n",
    "- classification through either \"classical\" approaches like SVM or machine learning and neural networks oriented methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to extract more features from the data in order to see how much better the classifiers perform\n",
    "Instead of extracting only MFCC and spectral centroid, I will be extracting chroma vector, zero crossing rate, spectral contrast, rolloff and bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new extraction function\n",
    "def extract_more_features(file_path):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path)\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    \n",
    "    # Extract spectral centroid\n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "\n",
    "    # Extract chroma features\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    \n",
    "    # Extract spectral contrast\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "\n",
    "    # Extact spectral roll-off\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    \n",
    "    # Extract spectral bandwidth\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    \n",
    "    # Extract zero crossing rate\n",
    "    zero_crossing = librosa.feature.zero_crossing_rate(y)\n",
    "    \n",
    "    return mfcc, centroid, chroma, zero_crossing, contrast, rolloff, bandwidth\n",
    "\n",
    "# Define the new process_audio_files function\n",
    "def process_audio_files_2(file_paths):\n",
    "    data = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # Extract features\n",
    "            mfcc, centroid, chroma, zero_crossing, contrast, rolloff, bandwidth = extract_more_features(file_path)\n",
    "            \n",
    "            # Calculate statistics for MFCC features\n",
    "            mfcc_statistics = calculate_statistics(mfcc)\n",
    "            # Calculate statistics for spectral centroid\n",
    "            centroid_statistics = calculate_statistics(centroid)\n",
    "            # Calculate statistics for chroma features\n",
    "            chroma_statistics = calculate_statistics(chroma)\n",
    "            # Calculate statistics for zero crossing rate\n",
    "            zero_crossing_statistics = calculate_statistics(zero_crossing)\n",
    "            # Calculate statistics for spectral contrast\n",
    "            contrast_statistics = calculate_statistics(contrast)\n",
    "            # Calculate statistics for spectral roll-off\n",
    "            rolloff_statistics = calculate_statistics(rolloff)\n",
    "            # Calculate statistics for spectral bandwidth\n",
    "            bandwidth_statistics = calculate_statistics(bandwidth)\n",
    "            \n",
    "            # Store statistics and file id in a dictionary\n",
    "            # Careful : use lstrip and not just strip because it would remove all the 0s of the files ending with 0 (like 10 would become 1)\n",
    "            file_id = os.path.basename(file_path).split('.')[0].lstrip('0') # Extract track ID from file name\n",
    "            entry = {'track_id': file_id}\n",
    "            \n",
    "            # Add MFCC statistics to entry\n",
    "            for mfcc_number, mfcc_values in enumerate(mfcc):\n",
    "                for stat_name, stat_value in mfcc_statistics.items():\n",
    "                    entry[f'mfcc_{mfcc_number}_{stat_name}'] = stat_value[mfcc_number]           \n",
    "            # Add centroid statistics to entry\n",
    "            for stat_name, stat_value in centroid_statistics.items():\n",
    "                entry[f'centroid_{stat_name}'] = stat_value[0]  # Spectral centroid has only one value per track\n",
    "            # Add chroma statistics to entry\n",
    "            for chroma_number, chroma_values in enumerate(chroma):\n",
    "                for stat_name, stat_value in chroma_statistics.items():\n",
    "                    entry[f'chroma_{chroma_number}_{stat_name}'] = stat_value[chroma_number]\n",
    "            # Add zero crossing rate statistics to entry\n",
    "            for stat_name, stat_value in zero_crossing_statistics.items():\n",
    "                entry[f'zero_crossing_{stat_name}'] = stat_value[0]  # Zero crossing rate has only one value per track\n",
    "            # Add spectral contrast statistics to entry\n",
    "            for contrast_number, contrast_values in enumerate(contrast):\n",
    "                for stat_name, stat_value in contrast_statistics.items():\n",
    "                    entry[f'contrast_{contrast_number}_{stat_name}'] = stat_value[contrast_number]\n",
    "            # Add spectral roll-off statistics to entry\n",
    "            for rolloff_number, rolloff_values in enumerate(rolloff):\n",
    "                for stat_name, stat_value in rolloff_statistics.items():\n",
    "                    entry[f'rolloff_{rolloff_number}_{stat_name}'] = stat_value[rolloff_number]\n",
    "            # Add spectral bandwidth statistics to entry\n",
    "            for bandwidth_number, bandwidth_values in enumerate(bandwidth):\n",
    "                for stat_name, stat_value in bandwidth_statistics.items():\n",
    "                    entry[f'bandwidth_{bandwidth_number}_{stat_name}'] = stat_value[bandwidth_number]\n",
    "            \n",
    "            data.append(entry)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing track {os.path.basename(file_path).split('.')[0].lstrip('0')}: {e}\")\n",
    "            continue\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the new function with the first two files to check for errors and execution time\n",
    "file_paths = [pathlist[0], pathlist[1]]\n",
    "df = pd.DataFrame(process_audio_files_2(file_paths))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split list into chunks\n",
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        #use yield instead of return to create a generator\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "# Process files in chunks\n",
    "chunk_size = 100\n",
    "for i, chunk in enumerate(chunks(pathlist, chunk_size)):\n",
    "    print(f\"Processing chunk {i+1}...\")\n",
    "    df = pd.DataFrame(process_audio_files_2(chunk))\n",
    "    if i == 0:\n",
    "        # Save header only for the first chunk\n",
    "        # We can use index = False because the index is not important in this case\n",
    "        df.to_csv('data/more_extracted_features.csv', index=False)\n",
    "    else:\n",
    "        # Append data without header for subsequent chunks\n",
    "        df.to_csv('data/more_extracted_features.csv', mode='a', index=False, header=False)\n",
    "    print(f\"Saved processed data for chunk {i+1}\")\n",
    "\n",
    "print(\"All chunks processed and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
